# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Cherry.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets, Qt
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
import os,sys
import shutil
import subprocess
import random
import pandas as pd
import numpy as np
import pickle as pkl
import scipy as sp
import networkx as nx
import scipy
import scipy.sparse
import scipy.stats as stats
import scipy.sparse as sparse
import markov_clustering as mc
import math
#from models.PhaGCN.scripts.ulity import *
#from models.PhaGCN.scripts.preprocessing import *
#from models.PhaGCN.scripts.cnnscript import *
from shutil import which
import shutil
from collections import Counter
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Blast.Applications import NcbiblastnCommandline
#from models.PhaGCN.Models.phamer import Transformer
#from models.PhaGCN.Models.CAPCNN import WCNN
#from models.PhaGCN.Models.PhaGCN import GCN
#from models.PhaGCN.Models import Cherry
from scipy.special import softmax
#from models.PhaGCN.scripts.data import load_data, preprocess_features, preprocess_adj, sample_mask
from torch import nn
from torch import optim
from torch.nn import functional as F

# QtWidgets.QWidget 要与 ui 窗口一致 QWidget 对应 QWidget; QMainWindow 对应 QMainWindow
class winTest(QtWidgets.QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle('My Browser')
        self.setStyleSheet("background-image: url(./logo/backgroundpage.png)")

    """对QDialog类重写，实现一些功能"""

    def closeEvent(self, event):
        """
        重写closeEvent方法，实现dialog窗体关闭时执行一些代码
        :param event: close()触发的事件
        :return: None
        """
        try:
            if os.path.exists(out_tmp):
                os.remove(out_tmp)
            else:
                return None  # 设置正常退出
        except:
            return None  # 设置正常退出


class WorkThread(QThread):
    # 自定义信号对象
    trigger = pyqtSignal(str)

    def __int__(self):
        # 初始化函数
        super(WorkThread, self).__init__()

    def run(self):
        try:
            midfolder = out_dir + '/midfolder'
            rootpth = out_dir
            db_dir = path + '/models/Cherry/database'
            parampth = path + '/models/Cherry/parameters'
            threads = 2
            topk = 1

            def translation(inpth, outpth, infile, outfile):
                prodigal = path + "/tools/prodigal/prodigal.exe"

                prodigal_cmd = f'{prodigal} -i {inpth}/{infile} -a {outpth}/{outfile} -f gff -p meta'
                print("Running prodigal...")
                _ = subprocess.check_call(prodigal_cmd, shell=True, stdout=subprocess.DEVNULL,
                                          stderr=subprocess.DEVNULL)

            def check_path(pth):
                if not os.path.isdir(pth):
                    os.makedirs(pth)

            def run_diamond(diamond_db, outpth, infile, tool, threads, path):
                # running alignment
                diamond_cmd = path + f'/tools/diamond/diamond_0_9_14.exe blastp --outfmt 5 --threads {threads} --sensitive -d {diamond_db} -q {outpth}/{infile} -o {outpth}/{tool}_results.xml -k 5'
                print("Running Diamond...")
                _ = subprocess.check_call(diamond_cmd, shell=True, stdout=subprocess.DEVNULL,
                                          stderr=subprocess.DEVNULL)
                content = open(f'{outpth}/{tool}_results.xml', 'r').read()
                content = content.replace('&', '')
                with open(f'{outpth}/{tool}_results.xml', 'w') as file:
                    file.write(content)

            def convert_xml(outpth, tool, scripts):
                def select_tab(file1, file2):
                    f = open(file1)
                    with open(file2, 'w') as w:
                        for i in f:
                            i = i.strip().split('\t')
                            print(i[0])
                            if i[0] != i[1]:
                                line = i[0] + ' ' + i[1] + ' ' + i[10] + '\n'
                                w.write(line)
                    w.close()

                # running alignment
                diamond_cmd = 'python.exe ' + f'{scripts}/blastxml_to_tabular.py -o {outpth}/{tool}_results.tab -c qseqid,sseqid,pident,length,mismatch,gapopen,qstart,qend,sstart,send,evalue {outpth}/{tool}_results.xml'
                _ = subprocess.check_call(diamond_cmd, shell=True, stdout=subprocess.DEVNULL,
                                          stderr=subprocess.DEVNULL)
                diamond_out_fp = f"{outpth}/{tool}_results.tab"
                database_abc_fp = f"{outpth}/{tool}_results.abc"
                select_tab(diamond_out_fp, database_abc_fp)

            def cat_fun1(df1, df2, df3, df4):
                with open(df4, 'w') as w:
                    f1 = open(df1)
                    f2 = open(df2)
                    f3 = open(df3)
                    for i in f1:
                        line = i
                        w.write(line)

                    for j in f2:
                        line = j
                        w.write(line)

                    for n in f3:
                        line = n
                        w.write(line)
                w.close()

            def cat_fun2(df1, df2, df3):
                with open(df3, 'w') as w:
                    f1 = open(df1)
                    f2 = open(df2)
                    for i in f1:
                        line = i
                        w.write(line)

                    for j in f2:
                        line = j
                        w.write(line)
                w.close()

            def load_mcl_clusters(fi):
                # Read MCL
                with open(fi) as f:
                    c = [line.rstrip("\n").split("\t") for line in f]
                c = [x for x in c if len(c) > 1]
                nb_clusters = len(c)
                formatter = "PC_{{:>0{}}}".format(int(round(np.log10(nb_clusters)) + 1))
                name = [formatter.format(str(i)) for i in range(nb_clusters)]
                size = [len(i) for i in c]
                clusters_df = pd.DataFrame({"size": size, "pc_id": name}).set_index("pc_id")
                return clusters_df, name, c

            def build_clusters(fp, gene2genome):
                # Read MCL
                clusters_df, name, c = load_mcl_clusters(fp)
                print("Using MCL to generate PCs.")
                # Assign each prot to its cluster
                gene2genome.set_index("protein_id", inplace=True)  # id, contig, keywords, cluster
                for prots, clust in zip(c, name):
                    try:
                        gene2genome.loc[prots, "cluster"] = clust
                    except KeyError:
                        prots_in = [p for p in prots if p in gene2genome.index]
                        not_in = frozenset(prots) - frozenset(prots_in)
                        print("{} protein(s) without contig: {}".format(len(not_in), not_in))
                        gene2genome.loc[prots_in, "cluster"] = clust
                # Keys
                for clust, prots in gene2genome.groupby("cluster"):
                    clusters_df.loc[clust, "annotated"] = prots.keywords.count()
                    if prots.keywords.count():
                        keys = ";".join(prots.keywords.dropna().values).split(";")
                        key_count = {}
                        for k in keys:
                            k = k.strip()
                            try:
                                key_count[k] += 1
                            except KeyError:
                                key_count[k] = 1
                        clusters_df.loc[clust, "keys"] = "; ".join(
                            ["{} ({})".format(x, y) for x, y in key_count.items()])
                gene2genome.reset_index(inplace=True)
                clusters_df.reset_index(inplace=True)
                profiles_df = gene2genome.loc[:, ["contig_id", "cluster"]].drop_duplicates()
                profiles_df.columns = ["contig_id", "pc_id"]
                contigs_df = pd.DataFrame(gene2genome.fillna(0).groupby("contig_id").count().protein_id)
                contigs_df.index.name = "contig_id"
                contigs_df.columns = ["proteins"]
                contigs_df.reset_index(inplace=True)
                return gene2genome, clusters_df, profiles_df, contigs_df

            def mcl_cal(input, merge_new, output):
                df = pd.read_csv(input,
                                 sep=' ',
                                 header=None)

                df[2][df[2] >= 200] = 200
                df[2][df[2] == 0] = 200
                df[2][df[2] < 200] = round(-(np.log10(df[2])), 5)

                lis1 = df[0].tolist()
                lis2 = df[1].tolist()
                lis = lis1 + lis2
                df.to_csv(merge_new, sep=' ', index=None, header=None)
                my_dic = dict.fromkeys(lis)
                result_list = list(my_dic)

                dic = {}
                count = 0
                for i in result_list:
                    dic[count] = i
                    count += 1

                data = pd.read_csv(merge_new,
                                   sep=' ',
                                   header=None)

                G = nx.Graph()
                G.add_nodes_from(data[0], bipartite=0)
                G.add_nodes_from(data[1], bipartite=1)
                edge_weight_list = data.apply(lambda x: tuple(x), axis=1).values.tolist()
                G.add_weighted_edges_from(edge_weight_list)
                A = nx.adjacency_matrix(G)

                del df, data, lis, lis1, lis2, my_dic, result_list

                result = mc.run_mcl(A, inflation=2)
                clusters = mc.get_clusters(result)

                with open(os.path.dirname(output) + '/mcl_tmp.txt', 'w') as w:
                    for i in clusters:
                        i = list(i)
                        line = ''
                        count = 1
                        for j in i:
                            if count == len(i):
                                line = line + dic[j] + '\n'
                                w.write(line)
                            line = line + dic[j] + '\t'
                            count += 1
                w.close()

                with open(output, 'w') as w:
                    with open(os.path.dirname(output) + '/mcl_tmp.txt', 'r') as f:
                        lines = f.readlines()
                        lines.sort(key=lambda x: len(x.strip().split('\t')), reverse=True)
                        for line in lines:
                            w.write(line)
                w.close()

                os.remove(os.path.dirname(output) + '/mcl_tmp.txt')
                os.remove(os.path.dirname(output) + '/cherry_merged.abc')

            def create_network(matrix, singletons, thres=1, max_sig=1000):
                contigs, pcs = matrix.shape
                pcs += singletons.sum()
                # Number of comparisons
                T = 0.5 * contigs * (contigs - 1)
                logT = np.log10(T)
                number_of_pc = matrix.sum(1) + singletons
                number_of_pc = number_of_pc.A1  # Transform into a flat array
                # Number of common protein clusters between two contigs, tuple + commons
                commons_pc = matrix.dot(sparse.csr_matrix(matrix.transpose(), dtype=int))
                S = sparse.lil_matrix((contigs, contigs))
                total_c = float(commons_pc.getnnz())
                i = 0  # Display
                for A, B in zip(*commons_pc.nonzero()):  # For A & B sharing contigs
                    if A != B:
                        a, b = sorted([number_of_pc[A], number_of_pc[B]])
                        pval = stats.hypergeom.sf(commons_pc[A, B] - 1, pcs, a, b)
                        sig = min(max_sig, np.nan_to_num(-np.log10(pval) - logT))
                        if sig > thres:
                            S[min(A, B), max(A, B)] = sig
                        # Display
                        i += 1
                        if i % 1000 == 0:
                            sys.stdout.write(".")
                        if i % 10000 == 0:
                            sys.stdout.write("{:6.2%} {}/{}\n".format(i / total_c, i, total_c))
                S += S.T  # Symmetry
                S = S.tocsr()
                if len(S.data) != 0:
                    print(
                        "Hypergeometric contig-similarity network:\n {0:10} contigs,\n {1:10} edges (min:{2:.2}"
                        "max: {3:.2}, threshold was {4})".format(contigs, S.getnnz(), S.data.min(),
                                                                 S.data.max(),
                                                                 thres))
                else:
                    raise ValueError("No edge in the similarity network !")
                return S

            def to_clusterer(matrix, fi, contigs=None, names=None):
                names = contigs if names is None else names
                names = names.set_index("pos").contig_id
                with open(fi, "wt") as f:
                    matrix = sparse.dok_matrix(matrix)
                    for r, c in zip(*matrix.nonzero()):
                        f.write(" ".join([str(x) for x in (names[r], names[c], matrix[r, c])]))
                        f.write("\n")
                print("Saving network in file {0} ({1} lines).".format(fi, matrix.getnnz()))
                return fi

            if not os.path.isfile(contigs):
                print('cannot find the file')

            if not os.path.exists(db_dir):
                print(f'Database directory {db_dir} missing or unreadable')

            check_path(out_dir)
            check_path(midfolder)

            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            if device == 'cpu':
                print("running with cpu")
                torch.set_num_threads(threads)

            rec = []
            for record in SeqIO.parse(contigs, 'fasta'):
                if len(record.seq) > float(length_len):
                    rec.append(record)

            SeqIO.write(rec, f'{rootpth}/filtered_contigs.fa', 'fasta')

            ###############################################################
            ########################## Cherry  ############################
            ###############################################################
            translation(rootpth, rootpth, 'filtered_contigs.fa', 'test_protein.fa')
            shutil.copyfile(f"{rootpth}/filtered_contigs.fa", f"{rootpth}/phage_contigs.fa")

            nucl = []
            protein = []
            for record in SeqIO.parse(f"{rootpth}/phage_contigs.fa", 'fasta'):
                nucl.append(record)

            for record in SeqIO.parse(f"{rootpth}/test_protein.fa", 'fasta'):
                protein.append(record)

            SeqIO.write(nucl, f'{rootpth}/checked_phage_contigs.fa', "fasta")
            SeqIO.write(protein, f'{rootpth}/checked_phage_protein.fa', "fasta")

            single_pth = rootpth + "/CNN_temp/single"
            cnninput_pth = rootpth + "/CNN_temp/input"
            cherryinput_pth = midfolder + "/cherry"
            check_path(single_pth)
            check_path(cnninput_pth)
            check_path(cherryinput_pth)

            contig2name = {}
            with open(f"{midfolder}/cherry_name_list.csv", 'w') as list_out:
                list_out.write("Contig,idx\n")
                for contig_id, record in enumerate(SeqIO.parse(f'{rootpth}/checked_phage_contigs.fa', "fasta")):
                    name = f"Cherry_{str(contig_id)}"
                    list_out.write(record.id + "," + name + "\n")
                    contig2name[record.id] = name
                    record.id = name
                    _ = SeqIO.write(record, f"{single_pth}/{name}.fa", "fasta")

            rename_rec = []
            for record in SeqIO.parse(f'{rootpth}/checked_phage_protein.fa', "fasta"):
                old_name = record.id
                idx = old_name.rsplit('_', 1)[1]
                record.id = contig2name[old_name.rsplit('_', 1)[0]] + "_" + idx
                rename_rec.append(record)

            SeqIO.write(rename_rec, f'{midfolder}/cherry_renamed_protein.fa', 'fasta')

            # generate 4mer feature
            cherrypth = f'{midfolder}/cherry'
            check_path(cherrypth)

            test_virus, test_virus2id = return_4mer(f'{rootpth}/CNN_temp/single/')
            pkl.dump(test_virus2id, open(f'{cherrypth}/test_virus.dict', 'wb'))
            pkl.dump(test_virus, open(f'{cherrypth}/test_virus.F', 'wb'))

            try:
                make_diamond_cmd = path + f'/tools/diamond/diamond_0_9_14.exe makedb --threads {threads} --in {midfolder}/cherry_renamed_protein.fa -d {cherrypth}/test_database.dmnd'
                print("Creating Diamond database...")
                _ = subprocess.check_call(make_diamond_cmd, shell=True)
            except:
                print("database failed")

            run_diamond(f'{db_dir}/cherry_database.dmnd', midfolder,
                        'cherry_renamed_protein.fa',
                        'cherry', threads, path)

            os.chdir(path + '/python')
            convert_xml(midfolder, 'cherry', path + '/models/Cherry/scripts')
            os.chdir(path)

            if os.path.getsize(f'{midfolder}/cherry_results.abc') == 0:
                Accession = []
                Length_list = []
                Pred_tmp = []
                for record in SeqIO.parse(f'{contigs}', 'fasta'):
                    Accession.append(record.id)
                    Length_list.append(len(record.seq))
                    Pred_tmp.append('unknown')

                df = pd.DataFrame(
                    {"Accession": Accession, "Pred": ['unknown'] * len(Accession), "Score": [0] * len(Accession)})
                df.to_csv(f"{out_dir}/cherry_prediction.csv", index=None)

            run_diamond(f'{cherrypth}/test_database.dmnd', midfolder,
                        'cherry_renamed_protein.fa',
                        'cherry_test', threads, path)

            os.chdir(path + '/python')
            convert_xml(midfolder, 'cherry_test', path + '/models/Cherry/scripts')
            os.chdir(path)

            database_abc_fp = f"{midfolder}/cherry_merged.abc"
            cat_fun1(f"{db_dir}/cherry_database.self-diamond.tab.abc", f"{midfolder}/cherry_results.abc",
                     f"{midfolder}/cherry_test_results.abc", database_abc_fp)

            blastp = pd.read_csv(database_abc_fp, sep=' ', names=["contig", "ref", "e-value"])
            protein_id = sorted(list(set(blastp["contig"].values) | set(blastp["ref"].values)))
            contig_protein = [item for item in protein_id if "Cherry" == item.split("_")[0]]
            contig_id = [item.rsplit("_", 1)[0] for item in contig_protein]
            description = ["hypothetical protein" for item in contig_protein]
            gene2genome = pd.DataFrame({"protein_id": contig_protein, "contig_id": contig_id, "keywords": description})
            gene2genome.to_csv(f"{midfolder}/cherry_contig_gene_to_genome.csv", index=None)

            cat_fun2(f"{db_dir}/cherry/database_gene_to_genome.csv",
                     f"{midfolder}/cherry_contig_gene_to_genome.csv",
                     f"{midfolder}/cherry_gene_to_genome.csv")

            gene2genome_fp = f"{midfolder}/cherry_gene_to_genome.csv"
            gene2genome_df = pd.read_csv(gene2genome_fp, sep=',', header=0)

            # Parameters for MCL
            pc_overlap, pc_penalty, pc_haircut, pc_inflation = 0.8, 2.0, 0.1, 2.0
            mcl_cal(database_abc_fp, midfolder + '/cherry_merged.abc', midfolder + '/res.txt')
            print("Building the cluster and profiles (this may take some time...)")

            protein_df, clusters_df, profiles_df, contigs_df = build_clusters(midfolder + '/res.txt',
                                                                              gene2genome_df)
            print("Saving files")

            dfs = [gene2genome_df, contigs_df, clusters_df]
            names = ['proteins', 'contigs', 'pcs']

            for name, df in zip(names, dfs):
                fn = "Cyber_cherry_{}.csv".format(name)
                fp = f'{midfolder}' + '/' + fn
                index_id = name.strip('s') + '_id'
                df.set_index(index_id).to_csv(fp)

            # Replace names
            contigs_csv_df = contigs_df.copy()
            contigs_csv_df.index.name = "pos"
            contigs_csv_df.reset_index(inplace=True)

            pcs_csv_df = clusters_df.copy()
            profiles = profiles_df.copy()

            # Filtering the PC profiles that appears only once
            before_filter = len(profiles)
            cont_by_pc = profiles.groupby("pc_id").count().contig_id.reset_index()

            # get the number of contigs for each pcs and add it to the dataframe
            cont_by_pc.columns = ["pc_id", "nb_proteins"]
            pcs_csv_df = pd.merge(pcs_csv_df, cont_by_pc, left_on="pc_id", right_on="pc_id", how="left")
            pcs_csv_df.fillna({"nb_proteins": 0}, inplace=True)

            # Drop the pcs that <= 1 contig from the profiles.
            pcs_csv_df = pcs_csv_df[pcs_csv_df['nb_proteins'] > 1]  # .query("nb_contigs>1")
            at_least_a_cont = cont_by_pc[cont_by_pc['nb_proteins'] > 1]  # cont_by_pc.query("nb_contigs>1")
            profiles = profiles[profiles['pc_id'].isin(at_least_a_cont.pc_id)]
            pcs_csv_df = pcs_csv_df.reset_index(drop=True)
            pcs_csv_df.index.name = "pos"
            pcs_csv_df = pcs_csv_df.reset_index()

            matrix, singletons = build_pc_matrices(profiles, contigs_csv_df, pcs_csv_df)
            profiles_csv = {"matrix": matrix, "singletons": singletons}
            merged_df = contigs_csv_df
            merged_fp = cherrypth + '/merged_df.csv'
            merged_df.to_csv(merged_fp)

            ntw = create_network(matrix, singletons, thres=1, max_sig=300)
            fi = to_clusterer(ntw, f"{cherrypth}/intermediate.ntw", merged_df.copy())

            rec = []
            for file in os.listdir(f'{rootpth}/CNN_temp/single/'):
                for record in SeqIO.parse(f'{rootpth}/CNN_temp/single/{file}', 'fasta'):
                    rec.append(record)
            SeqIO.write(rec, f"{cherrypth}/test.fa", 'fasta')

            query_file = f"{cherrypth}/test.fa"
            db_virus_prefix = f"{db_dir}/virus_db/allVIRUS"
            output_file = f"{cherrypth}/virus_out.tab"
            virus_call = NcbiblastnCommandline(path + "/blast-BLAST_VERSION+/bin/blastn.exe",
                                               query=query_file,
                                               db=db_virus_prefix,
                                               out=output_file,
                                               outfmt="6 qseqid sseqid evalue pident length qlen", evalue=1e-10,
                                               task='megablast',
                                               max_target_seqs=1,
                                               perc_identity=90,
                                               num_threads=threads)
            virus_call()

            virus_pred = {}
            with open(output_file) as file_out:
                for line in file_out.readlines():
                    parse = line.replace("\n", "").split("\t")
                    virus = parse[0]
                    ref_virus = parse[1].split('|')[1]
                    ref_virus = ref_virus.split('.')[0]
                    ident = float(parse[-3])
                    length = float(parse[-2])
                    qlen = float(parse[-1])
                    if virus not in virus_pred and length / qlen > 0.95 and ident > 90:
                        virus_pred[virus] = ref_virus

            pkl.dump(virus_pred, open(f'{cherrypth}/virus_pred.dict', 'wb'))

            # Dump graph
            G = nx.Graph()
            # Create graph
            with open(f"{cherrypth}/intermediate.ntw") as file_in:
                for line in file_in.readlines():
                    tmp = line[:-1].split(" ")
                    node1 = tmp[0]
                    node2 = tmp[1]
                    G.add_edge(node1, node2, weight=1)

            graph = f"{cherrypth}/phage_phage.ntw"
            with open(graph, 'w') as file_out:
                for node1 in G.nodes():
                    for _, node2 in G.edges(node1):
                        _ = file_out.write(node1 + "," + node2 + "\n")

            query_file = f"{cherrypth}/test.fa"
            db_host_crispr_prefix = f"{db_dir}/crispr_db/allCRISPRs"
            output_file = f"{cherrypth}/crispr_out.tab"
            crispr_call = NcbiblastnCommandline(path + "/blast-BLAST_VERSION+/bin/blastn.exe",
                                                query=query_file,
                                                db=db_host_crispr_prefix,
                                                out=output_file,
                                                outfmt="6 qseqid sseqid evalue pident length slen",
                                                evalue=1, gapopen=10, penalty=-1,
                                                gapextend=2, word_size=7, dust='no',
                                                task='blastn-short', perc_identity=90,
                                                num_threads=threads)
            crispr_call()

            crispr_pred = {}
            with open(output_file) as file_out:
                for line in file_out.readlines():
                    parse = line.replace("\n", "").split("\t")
                    virus = parse[0]
                    prokaryote = parse[1].split('|')[1]
                    prokaryote = prokaryote.split('.')[0]
                    ident = float(parse[-3])
                    length = float(parse[-2])
                    slen = float(parse[-1])
                    if virus not in crispr_pred:
                        if length / slen > 0.95 or ident > 95:
                            crispr_pred[virus] = prokaryote

            pkl.dump(crispr_pred, open(f'{cherrypth}/crispr_pred.dict', 'wb'))

            blast_database_out = f'{db_dir}/blast_db/'
            blast_tab_out = f'{cherrypth}/blast_tab'
            all_blast_tab = f'{cherrypth}/all_blast_tab'
            check_path(blast_database_out)
            check_path(blast_tab_out)
            check_path(all_blast_tab)

            # database only
            genome_list = os.listdir(f'{db_dir}/prokaryote')
            for genome in genome_list:
                accession = genome.split(".")[0]
                blast_cmd = path + f'/blast-BLAST_VERSION+/bin/blastn.exe -query {cherrypth}/test.fa -db {blast_database_out}/{accession} -outfmt 6 -out {blast_tab_out}/{accession}.tab -num_threads {threads}'
                print(f"Running {accession} blastn...")
                _ = subprocess.check_call(blast_cmd, shell=True)

            for file in os.listdir(blast_tab_out):
                cat_fun2(f"{blast_tab_out}/{file}",
                         f"{db_dir}/blast_tab/{file}",
                         f"{all_blast_tab}/{file}")

            # add connections between prokaryotes and viruses
            tab_file_list = os.listdir(all_blast_tab)
            prokaryote2virus = {}
            for file in tab_file_list:
                prokaryote_id = file.split('.')[0]
                virus_id_list = []
                with open(f'{all_blast_tab}/{file}') as file_in:
                    for line in file_in.readlines():
                        tmp = line.split('\t')
                        virus_id = tmp[0]
                        try:
                            prokaryote2virus[prokaryote_id].append(virus_id)
                        except:
                            prokaryote2virus[prokaryote_id] = [virus_id]

            # De-duplication
            for key in prokaryote2virus:
                prokaryote2virus[key] = list(set(prokaryote2virus[key]))

            # Save the virus-host graph
            with open(f"{cherrypth}/phage_host.ntw", 'w') as file_out:
                for prokaryote in prokaryote2virus:
                    for virus in prokaryote2virus[prokaryote]:
                        _ = file_out.write(prokaryote + "," + virus + "\n")

            phage_phage_ntw = f"{cherrypth}/phage_phage.ntw"
            phage_host_ntw = f"{cherrypth}/phage_host.ntw"

            # Add virus-virus edges
            G = nx.Graph()
            with open(phage_phage_ntw) as file_in:
                for line in file_in.readlines():
                    tmp = line[:-1].split(",")
                    node1 = tmp[0].split('.')[0]
                    node2 = tmp[1].split('.')[0]
                    G.add_edge(node1, node2, weight=1)

            # Add blastn edges
            with open(phage_host_ntw) as file_in:
                for line in file_in.readlines():
                    tmp = line[:-1].split(",")
                    node1 = tmp[0].split('.')[0]
                    node2 = tmp[1].split('.')[0]
                    G.add_edge(node1, node2, weight=1)

            bacteria_df = pd.read_csv(f'{db_dir}/cherry/prokaryote.csv')
            virus_df = pd.read_csv(f'{db_dir}/cherry/virus.csv')

            bacteria_list = os.listdir(f'{db_dir}/prokaryote/')
            bacteria_list = [name.split('.')[0] for name in bacteria_list]

            # add crispr edges
            species2bacteria = {bacteria_df[bacteria_df['Accession'] == item]['Species'].values[0]: item for item in
                                bacteria_list}
            crispr_pred = pkl.load(open(f'{cherrypth}/crispr_pred.dict', 'rb'))
            for virus, host in crispr_pred.items():
                if host in species2bacteria:
                    G.add_edge(virus, species2bacteria[host])

            # add dataset edges
            for bacteria in bacteria_list:
                species = bacteria_df[bacteria_df['Accession'] == bacteria]['Species'].values[0]
                phage_list = virus_df[virus_df['Species'] == species]['Accession'].values
                for phage in phage_list:
                    if phage in G.nodes():
                        G.add_edge(bacteria, phage, weight=1)

            # dump the graph G
            with open(f'{midfolder}/cherry_graph.csv', 'w') as file:
                file.write('Source,Target\n')
                for node in G.nodes():
                    for _, neighbor in G.edges(node):
                        file.write(f'{node},{neighbor}\n')

            virus2id = pkl.load(open(f"{db_dir}/cherry/virus.dict", 'rb'))
            virusF = pkl.load(open(f"{db_dir}/cherry/virus.F", 'rb'))
            prokaryote2id = pkl.load(open(f"{db_dir}/cherry/prokaryote.dict", 'rb'))
            prokaryoteF = pkl.load(open(f"{db_dir}/cherry/prokaryote.F", 'rb'))

            test_virus2id = pkl.load(open(f"{cherrypth}/test_virus.dict", 'rb'))
            test_virusF = pkl.load(open(f"{cherrypth}/test_virus.F", 'rb'))
            test_prokaryote2id = {}

            node_feature = []
            for node in G.nodes():
                # if prokaryote node
                if node in prokaryote2id.keys():
                    node_feature.append(prokaryoteF[prokaryote2id[node]])
                # if virus node
                elif node in virus2id.keys():
                    node_feature.append(virusF[virus2id[node]])
                # if test virus node
                elif node in test_virus2id.keys():
                    node_feature.append(test_virusF[test_virus2id[node]])
                # # if test prokaryote node
                # elif node in test_prokaryote2id.keys():
                #     node_feature.append(test_prokaryoteF[test_prokaryote2id[node]])
                else:
                    print(f"node error {node}")

            node_feature = np.array(node_feature)

            crispr_pred = pkl.load(open(f'{cherrypth}/crispr_pred.dict', 'rb'))
            virus_pred = pkl.load(open(f'{cherrypth}/virus_pred.dict', 'rb'))
            virus_df = virus_df
            prokaryote_df = bacteria_df

            idx = 0
            test_id = {}
            node2label = {}
            cnt = 0
            for node in G.nodes():
                # if test virus node
                if "Cherry" in node:
                    neighbor_label = []
                    for _, neighbor in G.edges(node):
                        if neighbor in virus2id.keys():
                            virus_label = virus_df[virus_df['Accession'] == neighbor]['Species'].values[0]
                            neighbor_label.append(virus_label)
                        elif neighbor in prokaryote2id.keys():
                            prokaryote_label = prokaryote_df[prokaryote_df['Accession'] == neighbor]['Species'].values[0]
                            neighbor_label.append(prokaryote_label)
                    # subgraph
                    if len(set(neighbor_label)) == 1:
                        node2label[node] = neighbor_label[0]
                        test_id[node] = 1
                    # CRISPR
                    elif node in crispr_pred:
                        node2label[node] = prokaryote_df[prokaryote_df['Accession'] == crispr_pred[node]]['Species'].values[
                            0]
                        test_id[node] = 1
                    elif node in virus_pred:
                        node2label[node] = virus_df[virus_df['Accession'] == virus_pred[node]]['Species'].values[0]
                        test_id[node] = 1
                    # unlabelled
                    else:
                        node2label[node] = 'unknown'
                        test_id[node] = 2
                # if phage or host node
                elif node in prokaryote2id.keys():
                    prokaryote_label = prokaryote_df[prokaryote_df['Accession'] == node]['Species'].values[0]
                    node2label[node] = prokaryote_label
                    test_id[node] = 0
                elif node in test_prokaryote2id.keys():
                    prokaryote_label = prokaryote_df[prokaryote_df['Accession'] == node]['Species'].values[0]
                    node2label[node] = prokaryote_label
                    test_id[node] = 0
                elif node in virus2id.keys():
                    virus_label = virus_df[virus_df['Accession'] == node]['Species'].values[0]
                    node2label[node] = virus_label
                    test_id[node] = 0
                else:
                    print("Error: " + node)
                idx += 1

            # check subgraph situation 1
            for sub in nx.connected_components(G):
                flag = 0
                for node in sub:
                    if "Cherry" not in node:
                        flag = 1
                # use CRISPR
                if not flag:
                    CRISPR_label = ""
                    CRISPR_cnt = 0
                    for node in sub:
                        if node in crispr_pred:
                            CRISPR_cnt += 1
                            CRISPR_label = crispr_pred[node]
                    if CRISPR_cnt == 1:
                        for node in sub:
                            node2label[node] = CRISPR_label

            # check subgraph situation 2
            for sub in nx.connected_components(G):
                sub_label = []
                for node in sub:
                    if node in virus2id.keys():
                        virus_label = virus_df[virus_df['Accession'] == node]['Species'].values[0]
                        sub_label.append(virus_label)
                    elif node in prokaryote2id.keys():
                        prokaryote_label = prokaryote_df[prokaryote_df['Accession'] == node]['Species'].values[0]
                        sub_label.append(prokaryote_label)
                if len(set(sub_label)) == 1:
                    for node in sub:
                        node2label[node] = sub_label[0]
                        test_id[node] = 1
                elif len(set(sub_label)) == 0:
                    for node in sub:
                        node2label[node] = 'unknown'
                        test_id[node] = 3

            # check graph situation 3
            for node in G.nodes():
                # if test virus node
                if "Cherry" in node:
                    neighbor_label = []
                    for _, neighbor in G.edges(node):
                        if neighbor in virus2id.keys():
                            virus_label = virus_df[virus_df['Accession'] == neighbor]['Species'].values[0]
                            neighbor_label.append(virus_label)
                        elif neighbor in prokaryote2id.keys():
                            prokaryote_label = prokaryote_df[prokaryote_df['Accession'] == neighbor]['Species'].values[0]
                            neighbor_label.append(prokaryote_label)
                    try:
                        if not neighbor_label:
                            continue
                        cnt = Counter(neighbor_label)
                        most_cnt = cnt.most_common()[0]
                        if len(set(sub_label)) == 0:
                            continue
                        if most_cnt[1] - 1 / len(set(sub_label)) > 0.3:
                            node2label[node] = most_cnt[0]
                            test_id[node] = 1
                    except:
                        continue

            id2node = {idx: node for idx, node in enumerate(G.nodes())}
            node2id = {node: idx for idx, node in enumerate(G.nodes())}

            adj = nx.adjacency_matrix(G)
            pkl.dump(adj, open(f"{cherrypth}/graph.list", "wb"))
            pkl.dump(node_feature, open(f"{cherrypth}/feature.list", "wb"))
            pkl.dump(node2label, open(f"{cherrypth}/node2label.dict", "wb"))
            pkl.dump(id2node, open(f"{cherrypth}/id2node.dict", "wb"))
            pkl.dump(node2id, open(f"{cherrypth}/node2id.dict", "wb"))
            pkl.dump(test_id, open(f"{cherrypth}/test_id.dict", "wb"))

            # model
            trainable_host = []
            for file in os.listdir(f'{db_dir}/prokaryote/'):
                trainable_host.append(file.rsplit('.', 1)[0])

            idx_test = test_id
            host2id = {}
            label2hostid = {}
            trainable_host_idx = []
            trainable_label = []
            for idx, node in id2node.items():
                # if prokaryote
                if node in trainable_host:
                    host2id[node] = idx
                    trainable_host_idx.append(idx)
                    trainable_label.append(node2label[node])
                    label2hostid[node2label[node]] = idx

            # pre-processing
            features = sp.sparse.csc_matrix(node_feature)
            print('adj:', adj.shape)
            print('features:', features.shape)

            # convert to torch tensor
            features = preprocess_features(features)
            supports = preprocess_adj(adj)
            num_classes = len(set(list(node2label.values()))) + 1
            # graph
            i = torch.from_numpy(features[0]).long().to(device)
            v = torch.from_numpy(features[1]).to(device)
            feature = torch.sparse.FloatTensor(i.t(), v, features[2]).float().to(device)
            feature = feature.to_dense()
            i = torch.from_numpy(supports[0]).long().to(device)
            v = torch.from_numpy(supports[1]).to(device)
            support = torch.sparse.FloatTensor(i.t(), v, supports[2]).float().to(device)
            support = support.to_dense()

            print('x :', feature)
            print('sp:', support)
            feat_dim = adj.shape[0]
            node_dim = feature.shape[1]

            # Definition of the model
            net = Cherry.encoder(feat_dim, node_dim, node_dim, 0)
            decoder = Cherry.decoder(node_dim, 128, 32)

            # Load pre-trained model
            encoder_dict = torch.load(f"{parampth}/cherry/Encoder_Species.pkl", map_location='cpu')
            decoder_dict = torch.load(f"{parampth}/cherry/Decoder_Species.pkl", map_location='cpu')
            net.load_state_dict(encoder_dict)
            decoder.load_state_dict(decoder_dict)

            net.to(device)
            decoder.to(device)

            # end-to-end training
            params = list(net.parameters()) + list(decoder.parameters())
            optimizer = optim.Adam(params, lr=0.001)  # args.learning_rate
            loss_func = nn.BCEWithLogitsLoss()

            # predicting host
            node2pred = {}
            with torch.no_grad():
                encode = net((feature, support))
                for i in range(len(encode)):
                    confident_label = 'unknown'
                    if idx_test[id2node[i]] == 0 or idx_test[id2node[i]] == 3:
                        continue
                    if idx_test[id2node[i]] == 1:
                        confident_label = node2label[id2node[i]]
                    virus_feature = encode[i]
                    pred_label_score = []
                    for label in set(trainable_label):
                        if label == confident_label:
                            pred_label_score.append((label, 10))
                            continue
                        prokaryote_feature = encode[label2hostid[label]]
                        pred = decoder(virus_feature - prokaryote_feature)
                        pred_label_score.append((label, torch.sigmoid(pred).detach().cpu().numpy()[0]))
                    node2pred[id2node[i]] = sorted(pred_label_score, key=lambda tup: tup[1], reverse=True)
                for virus in crispr_pred:
                    # if virus not in node2pred:
                    pred = prokaryote_df[prokaryote_df['Accession'] == crispr_pred[virus]]['Species'].values[0]
                    node2pred[virus] = [(pred, 1)]
                # dump the prediction
                with open(f"{midfolder}/cherry_mid_predict.csv", 'w') as file_out:
                    file_out.write('Contig,')
                    for i in range(topk):
                        file_out.write(f'Top_{i + 1}_label,Score_{i + 1},')
                    file_out.write('Type\n')
                    for contig in node2pred:
                        file_out.write(f'{contig},')
                        cnt = 1
                        for label, score in node2pred[contig]:
                            if cnt > topk:
                                break
                            cnt += 1
                            if score > 1:
                                score = 1
                            file_out.write(f'{label},{score:.2f},')
                        if contig in crispr_pred:
                            file_out.write(f'CRISPR')
                        else:
                            file_out.write(f'Predict')
                        file_out.write('\n')

            tmp_pred = pd.read_csv(f"{midfolder}/cherry_mid_predict.csv")
            name_list = pd.read_csv(f"{midfolder}/cherry_name_list.csv")
            prediction = tmp_pred.rename(columns={'Contig': 'idx'})
            contig_to_pred = pd.merge(name_list, prediction, on='idx')
            contig_to_pred = contig_to_pred.rename(columns={'Contig': 'Accession'})
            # contig_to_pred = contig_to_pred.drop(columns=['idx'])
            contig_to_pred.to_csv(f"{midfolder}/cherry_prediction.csv", index=None)

            # add no prediction (Nov. 13th)

            all_Contigs = contig_to_pred['Accession'].values
            all_Pred = contig_to_pred['Top_1_label'].values
            all_Score = contig_to_pred['Score_1'].values
            all_Type = contig_to_pred['Type'].values

            if len(set(all_Type)) == 1 and all_Type[0] == 'CRISPR':
                pass

            phage_contig = []
            filtered_contig = []
            length_dict = {}
            seq_dict = {}
            for record in SeqIO.parse(f'{contigs}', 'fasta'):
                length_dict[record.id] = len(record.seq)
                seq_dict[record.id] = str(record.seq)
                if len(record.seq) < float(length_len):
                    filtered_contig.append(record.id)
                else:
                    phage_contig.append(record.id)

            unpredict_contig = []
            for contig in phage_contig:
                if contig not in all_Contigs:
                    unpredict_contig.append(contig)

            all_Contigs = np.concatenate((all_Contigs, np.array(filtered_contig), np.array(unpredict_contig)))
            all_Pred = np.concatenate(
                (all_Pred, np.array(['filtered'] * len(filtered_contig)), np.array(['unknown'] * len(unpredict_contig))))
            all_Length = [length_dict[item] for item in all_Contigs]
            all_Score = np.concatenate(
                (all_Score, np.array([0] * len(filtered_contig)), np.array([0] * len(unpredict_contig))))
            all_Type = np.concatenate(
                (all_Type, np.array(['-'] * len(filtered_contig)), np.array(['-'] * len(unpredict_contig))))

            contig_to_pred = pd.DataFrame(
                {'Accession': all_Contigs, 'Length': all_Length, 'Pred': all_Pred, 'Score': all_Score, 'Type': all_Type})
            contig_to_pred.to_csv(f"{out_dir}/cherry_prediction.csv", index=None)

            self.trigger.emit('Finished!!!' + '\n' + 'cherry_prediction.csv is your result!!!')

        except Exception as ex:
            self.trigger.emit('Some errors have occurred, %s!' % ex)
class Cherry_Form(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.work = WorkThread()

    def setupUi(self, Form):
        Form.setObjectName("Form")
        Form.resize(683, 542)
        Form.setWindowIcon(QIcon("./logo/logo.ico"))
        Form.setStyleSheet("background-image: url(./logo/green_back.png);")
        self.gridLayout_6 = QtWidgets.QGridLayout(Form)
        self.gridLayout_6.setObjectName("gridLayout_6")
        self.gridLayout = QtWidgets.QGridLayout()
        self.gridLayout.setSpacing(0)
        self.gridLayout.setObjectName("gridLayout")
        self.textBrowser_2 = QtWidgets.QTextBrowser(Form)
        self.textBrowser_2.setStyleSheet("background-image: url(./logo/white.png)")
        self.textBrowser_2.setObjectName("textBrowser_2")
        self.gridLayout.addWidget(self.textBrowser_2, 2, 0, 1, 1)
        self.label_2 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(15)
        self.label_2.setFont(font)
        self.label_2.setAlignment(QtCore.Qt.AlignLeading|QtCore.Qt.AlignLeft|QtCore.Qt.AlignVCenter)
        self.label_2.setObjectName("label_2")
        self.gridLayout.addWidget(self.label_2, 1, 0, 1, 1)
        self.pushButton_4 = QtWidgets.QPushButton(Form)
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.pushButton_4.sizePolicy().hasHeightForWidth())
        self.pushButton_4.setSizePolicy(sizePolicy)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(15)
        self.pushButton_4.setFont(font)
        self.pushButton_4.setObjectName("pushButton_4")
        self.gridLayout.addWidget(self.pushButton_4, 8, 1, 1, 1)
        self.label_6 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(10)
        self.label_6.setFont(font)
        self.label_6.setAlignment(QtCore.Qt.AlignLeading|QtCore.Qt.AlignLeft|QtCore.Qt.AlignVCenter)
        self.label_6.setObjectName("label_6")
        self.gridLayout.addWidget(self.label_6, 7, 1, 1, 1)
        self.pushButton = QtWidgets.QPushButton(Form)
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.pushButton.sizePolicy().hasHeightForWidth())
        self.pushButton.setSizePolicy(sizePolicy)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(22)
        self.pushButton.setFont(font)
        self.pushButton.setStyleSheet("background-image: url(./logo/white.png)")
        self.pushButton.setObjectName("pushButton")
        self.gridLayout.addWidget(self.pushButton, 9, 1, 2, 1)
        self.label = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(19)
        self.label.setFont(font)
        self.label.setAlignment(QtCore.Qt.AlignCenter)
        self.label.setObjectName("label")
        self.gridLayout.addWidget(self.label, 0, 0, 1, 2)
        self.label_3 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(15)
        self.label_3.setFont(font)
        self.label_3.setAlignment(QtCore.Qt.AlignLeading|QtCore.Qt.AlignLeft|QtCore.Qt.AlignVCenter)
        self.label_3.setObjectName("label_3")
        self.gridLayout.addWidget(self.label_3, 4, 0, 1, 1)
        self.textBrowser_3 = QtWidgets.QTextBrowser(Form)
        self.textBrowser_3.setStyleSheet("background-image: url(./logo/white.png)")
        self.textBrowser_3.setObjectName("textBrowser_3")
        self.gridLayout.addWidget(self.textBrowser_3, 5, 0, 1, 1)
        self.pushButton_2 = QtWidgets.QPushButton(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.pushButton_2.setFont(font)
        self.pushButton_2.setObjectName("pushButton_2")
        self.gridLayout.addWidget(self.pushButton_2, 3, 0, 1, 1)
        self.label_5 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(15)
        self.label_5.setFont(font)
        self.label_5.setAlignment(QtCore.Qt.AlignLeading|QtCore.Qt.AlignLeft|QtCore.Qt.AlignVCenter)
        self.label_5.setObjectName("label_5")
        self.gridLayout.addWidget(self.label_5, 7, 0, 1, 1)
        self.pushButton_3 = QtWidgets.QPushButton(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.pushButton_3.setFont(font)
        self.pushButton_3.setObjectName("pushButton_3")
        self.gridLayout.addWidget(self.pushButton_3, 6, 0, 1, 1)
        self.textEdit = QtWidgets.QTextEdit(Form)
        self.textEdit.setStyleSheet("background-image: url(./logo/white.png)")
        self.textEdit.setObjectName("textEdit")
        self.gridLayout.addWidget(self.textEdit, 8, 0, 1, 1)
        self.label_4 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(19)
        self.label_4.setFont(font)
        self.label_4.setAlignment(QtCore.Qt.AlignCenter)
        self.label_4.setObjectName("label_4")
        self.gridLayout.addWidget(self.label_4, 9, 0, 1, 1)
        self.textBrowser = QtWidgets.QTextBrowser(Form)
        self.textBrowser.setStyleSheet("background-image: url(./logo/white.png)")
        self.textBrowser.setObjectName("textBrowser")
        self.gridLayout.addWidget(self.textBrowser, 10, 0, 1, 1)
        self.tableWidget = QtWidgets.QTableWidget(Form)
        self.tableWidget.setStyleSheet("background-image: url(./logo/white.png)")
        self.tableWidget.setObjectName("tableWidget")
        self.tableWidget.setColumnCount(5)
        self.tableWidget.setRowCount(0)
        item = QtWidgets.QTableWidgetItem()
        self.tableWidget.setHorizontalHeaderItem(0, item)
        item = QtWidgets.QTableWidgetItem()
        self.tableWidget.setHorizontalHeaderItem(1, item)
        item = QtWidgets.QTableWidgetItem()
        self.tableWidget.setHorizontalHeaderItem(2, item)
        item = QtWidgets.QTableWidgetItem()
        self.tableWidget.setHorizontalHeaderItem(3, item)
        item = QtWidgets.QTableWidgetItem()
        self.tableWidget.setHorizontalHeaderItem(4, item)
        self.gridLayout.addWidget(self.tableWidget, 2, 1, 5, 1)
        self.label_7 = QtWidgets.QLabel(Form)
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(15)
        self.label_7.setFont(font)
        self.label_7.setAlignment(QtCore.Qt.AlignCenter)
        self.label_7.setObjectName("label_7")
        self.gridLayout.addWidget(self.label_7, 1, 1, 1, 1)
        self.gridLayout_6.addLayout(self.gridLayout, 0, 0, 1, 1)

        self.retranslateUi(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)

        # button action
        self.pushButton.clicked.connect(self.calculation)
        self.pushButton_2.clicked.connect(self.read_file1)
        self.pushButton_3.clicked.connect(self.read_file2)
        self.pushButton_4.clicked.connect(self.table_read)

        ## default
        self.textBrowser_2.setPlaceholderText("D:/input/test.fa")
        self.textBrowser_3.setPlaceholderText("D:/output")
        self.textEdit.setPlaceholderText(" Contig length filter: 3000")

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate("Form", "Cherry"))
        self.label_2.setText(_translate("Form", "Input fasta file"))
        self.pushButton_4.setText(_translate("Form", "Table"))
        self.label_6.setText(_translate("Form", "If the program is finished, click \'Table\' to display the result"))
        self.pushButton.setText(_translate("Form", "Run"))
        self.label.setText(_translate("Form", "Cherry"))
        self.label_3.setText(_translate("Form", "Output folder"))
        self.pushButton_2.setText(_translate("Form", "Choose"))
        self.label_5.setText(_translate("Form", "Contig length"))
        self.pushButton_3.setText(_translate("Form", "Choose"))
        self.label_4.setText(_translate("Form", "Status"))
        item = self.tableWidget.horizontalHeaderItem(0)
        item.setText(_translate("Form", "Accession"))
        item = self.tableWidget.horizontalHeaderItem(1)
        item.setText(_translate("Form", "Length"))
        item = self.tableWidget.horizontalHeaderItem(2)
        item.setText(_translate("Form", "Pred"))
        item = self.tableWidget.horizontalHeaderItem(3)
        item.setText(_translate("Form", "Score"))
        item = self.tableWidget.horizontalHeaderItem(4)
        item.setText(_translate("Form", "Type"))
        self.label_7.setText(_translate("Form", "Result table"))


    def read_file1(self):
        openfile_name = QtWidgets.QFileDialog.getOpenFileName(self, 'choose file', '')[0]
        print(openfile_name)
        self.textBrowser_2.setText(openfile_name)


    def read_file2(self):
        openfile_name = QtWidgets.QFileDialog.getExistingDirectory(self, "choose file", "./")
        print(openfile_name)
        self.textBrowser_3.setText(openfile_name)

    def finished(self, str):
        self.textBrowser.setText(str)

    def calculation(self):
        try:
            def is_fasta(filename):
                with open(filename, "r") as handle:
                    fasta = SeqIO.parse(handle, "fasta")
                    return any(fasta)

            global contigs, out_dir, path, length_len, out_pred
            contigs = self.textBrowser_2.toPlainText()
            out_dir = self.textBrowser_3.toPlainText()

            out_pred = f"{out_dir}/cherry_prediction.csv"

            path = os.path.abspath('.')
            if '\\' in path:
                path = path.strip().split('\\')
                path = '/'.join(path)


            if 0 in [len(contigs), len(out_dir)]:
                QMessageBox.warning(self, "warning", "Please add correct file path!", QMessageBox.Cancel)
            else:
                if is_fasta(contigs) == False:
                    QMessageBox.critical(self, "error", "Check fasta file format!")
                else:
                    try:
                        self.textBrowser.setText(
                            'Running! please wait (25-30mins)' + '\n' + 'If no response,never close window!!!')
                        QApplication.processEvents()  # 逐条打印状态

                        length_len = str(self.textEdit.toPlainText())
                        if length_len == '':
                            length_len = 3000
                        else:
                            length_len = float(length_len)

                        # 启动线程, 运行 run 函数
                        self.work.start()
                        # 传送信号, 接受 run 函数执行完毕后的信号
                        self.work.trigger.connect(self.finished)

                    except:
                        QMessageBox.critical(self, "error", "Check parameters value!")

        except:
            QMessageBox.critical(self, "error", "Check fasta file format!")


    def table_read(self):
        try:
            global out_tmp
            out_p = os.path.dirname(out_pred)
            out_tmp = out_p + '/cherry_prediction_tmp.csv'

            with open(out_tmp, 'w') as w:
                f = open(out_pred)
                count = 0
                for line in f:
                    if count == 0:
                        print('1')
                    else:
                        w.write(line)
                        print(line)
                    count = count + 1
            w.close()

            f = open(out_tmp)
            count = 0
            for line in f:
                count = count + 1

            nrows = int(count)
            print(nrows)
            ncols = 5
            self.tableWidget.setRowCount(nrows)  # 设置行数
            self.tableWidget.setColumnCount(ncols)

            f = open(out_tmp)
            row_num = 0
            for line in f:
                print(line)
                li = line.strip().split(',')
                col_num = 0
                for i in li:
                    item = QTableWidgetItem(i)
                    print(item)
                    self.tableWidget.setItem(row_num, col_num, item)
                    print(row_num, col_num)
                    col_num = col_num + 1
                row_num = row_num + 1

        except:
            QMessageBox.critical(self, "error", "Please run program first!!!")


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    WT = QtWidgets.QWidget()
    WT = winTest()
    ui = Cherry_Form()
    ui.setupUi(WT)
    WT.show()
    sys.exit(app.exec_())

